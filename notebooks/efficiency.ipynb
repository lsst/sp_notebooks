{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of day_obs for data query\n",
    "import rubin_nights.dayobs_utils as rn_dayobs\n",
    "\n",
    "day_obs = rn_dayobs.day_obs_str_to_int(rn_dayobs.today_day_obs())\n",
    "n_days = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# On-sky Efficiency {params.day_obs_min} to {params.day_obs_max}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some configuration for password/RPS tokenfiles\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Who is running the notebook? Some of us have preferences ..\n",
    "username = getpass.getuser()\n",
    "# Where is the notebook running? (RSPs are 'special')\n",
    "current_location = os.getenv(\"EXTERNAL_INSTANCE_URL\", \"\")\n",
    "\n",
    "# RUBIN_SIM_DATA_DIR at usdf\n",
    "if \"usdf\" in current_location:\n",
    "    os.environ[\"RUBIN_SIM_DATA_DIR\"] = \"/sdf/data/rubin/shared/rubin_sim_data\"\n",
    "\n",
    "# TOKEN CONFIGURATION\n",
    "if current_location != \"\":\n",
    "    # You are on an rsp.\n",
    "    # You should use the default RSP values, whether summit/base/USDF.\n",
    "    tokenfile = None\n",
    "    site = None\n",
    "# If you are outside of an RSP? - just use USDF and your own USDF-RSP token\n",
    "# See https://rsp.lsst.io/guides/auth/creating-user-tokens.html\n",
    "# See also rubin_nights.get_access_token for information about the default locations for tokens (or overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import warnings\n",
    "import copy\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import colorcet as cc\n",
    "import skyproj\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from astropy.time import Time, TimeDelta\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from rubin_scheduler.scheduler.utils import SchemaConverter\n",
    "from rubin_scheduler.site_models import Almanac\n",
    "from rubin_scheduler.scheduler.features import Conditions\n",
    "from rubin_scheduler.utils import (\n",
    "    ddf_locations,\n",
    "    angular_separation,\n",
    "    approx_ra_dec2_alt_az,\n",
    "    Site,\n",
    "    SURVEY_START_MJD,\n",
    ")\n",
    "\n",
    "import rubin_sim.maf as maf\n",
    "from rubin_sim.data import get_baseline\n",
    "\n",
    "from rubin_nights import connections\n",
    "import rubin_nights.dayobs_utils as rn_dayobs\n",
    "import rubin_nights.plot_utils as rn_plots\n",
    "import rubin_nights.augment_visits as augment_visits\n",
    "import rubin_nights.rubin_scheduler_addons as rn_sch\n",
    "import rubin_nights.rubin_sim_addons as rn_sim\n",
    "import rubin_nights.observatory_status as observatory_status\n",
    "import rubin_nights.scriptqueue as scriptqueue\n",
    "import rubin_nights.scriptqueue_formatting as scriptqueue_formatting\n",
    "import rubin_nights.targets_and_visits as targets_and_visits\n",
    "\n",
    "import importlib\n",
    "\n",
    "from lsst_survey_sim import lsst_support, simulate_lsst, plot\n",
    "\n",
    "band_colors = rn_plots.PlotStyles.band_colors\n",
    "logging.getLogger(\"rubin_nights\").setLevel(logging.INFO)\n",
    "\n",
    "# %load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up connections to data (will use consdb, exposure log and narrative log)\n",
    "endpoints = connections.get_clients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_obs_max = day_obs\n",
    "day_obs_min = rn_dayobs.time_to_day_obs(\n",
    "    rn_dayobs.day_obs_to_time(day_obs_max) - TimeDelta(n_days, format=\"jd\")\n",
    ")\n",
    "day_obs_min = rn_dayobs.day_obs_str_to_int(day_obs_min)\n",
    "print(f\"Querying for lsstcam visits {day_obs_min} to {day_obs_max}\")\n",
    "\n",
    "one_day = TimeDelta(1, format=\"jd\")\n",
    "days = rn_dayobs.day_obs_to_time(day_obs_min) + one_day * np.arange(\n",
    "    0,\n",
    "    (rn_dayobs.day_obs_to_time(day_obs_max) - rn_dayobs.day_obs_to_time(day_obs_min)).jd\n",
    "    + 1,\n",
    ")\n",
    "day_obs_list = [\n",
    "    rn_dayobs.day_obs_str_to_int(rn_dayobs.time_to_day_obs(d)) for d in days\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Consdb data and add some flags for bad visits, filter changes, and calculate slew times and identify expected overheads vs. excess\n",
    "\n",
    "# We query all programs to get slewtimes and idle throughout entire night\n",
    "# But these are what will be considered \"science\"\n",
    "try:\n",
    "    from rubin_nights.reference_values import SCIENCE_PROGRAMS\n",
    "\n",
    "    programs = SCIENCE_PROGRAMS\n",
    "except ImportError:\n",
    "    programs = [\n",
    "        \"BLOCK-365\",\n",
    "        \"BLOCK-407\",\n",
    "        \"BLOCK-408\",\n",
    "        \"BLOCK-416\",\n",
    "        \"BLOCK-417\",\n",
    "        \"BLOCK-419\",\n",
    "        \"BLOCK-421\",\n",
    "    ]\n",
    "\n",
    "# Just a flag to make it clear if we're skipping retrieval from the consdb.\n",
    "# (this can make it much quicker to repeat this cell to tweak the inserts below)\n",
    "refresh_visits = True\n",
    "if refresh_visits:\n",
    "    skip_imgtypes = [\"bias\", \"flat\", \"dark\"]\n",
    "    query = (\n",
    "        \"select *, q.* from cdb_lsstcam.visit1 left join cdb_lsstcam.visit1_quicklook as q on visit1.visit_id = q.visit_id \"\n",
    "        f\"where visit1.day_obs >= {day_obs_min} and visit1.day_obs <= {day_obs_max} and img_type != 'bias' and img_type != 'flat' and img_type != 'dark'\"\n",
    "    )\n",
    "    visits = endpoints[\"consdb\"].query(query)\n",
    "    visits = augment_visits.augment_visits(visits, \"lsstcam\")\n",
    "    visits.reset_index(inplace=True)\n",
    "    visits.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "dome_open = observatory_status.get_dome_open_close(\n",
    "    rn_dayobs.day_obs_to_time(day_obs_min),\n",
    "    rn_dayobs.day_obs_to_time(day_obs_max) + TimeDelta(1, format=\"jd\"),\n",
    "    endpoints[\"efd\"],\n",
    ")\n",
    "\n",
    "wait_before_slew = 1.6\n",
    "settle = 1.5\n",
    "max_scatter = 10\n",
    "\n",
    "if len(visits) > 0:\n",
    "\n",
    "    cols = [\"overhead\", \"fault_idle\", \"program_change\", \"filter_change\", \"bad_flag\"]\n",
    "    new_df = pd.DataFrame(\n",
    "        np.zeros((len(visits), len(cols))), columns=cols, index=visits.index\n",
    "    )\n",
    "    visits = visits.merge(new_df, right_index=True, left_index=True)\n",
    "\n",
    "    # Flag science_program changes\n",
    "    program_change = np.where(\n",
    "        (visits.science_program[:-1].values != visits.science_program[1:].values)\n",
    "    )[0]\n",
    "    program_change = program_change + 1\n",
    "    pmask = np.zeros(len(visits))\n",
    "    pmask[0] = 1\n",
    "    pmask[program_change] = 1\n",
    "    visits[\"program_change\"] = pmask\n",
    "\n",
    "    # Flag filter changes\n",
    "    filter_change = np.where(\n",
    "        (visits.band[:-1].values != visits.band[1:].values)\n",
    "        & (visits.day_obs[:-1].values == visits.day_obs[1:].values)\n",
    "    )[0]\n",
    "    filter_change = filter_change + 1\n",
    "    fmask = np.zeros(len(visits))\n",
    "    fmask[filter_change] = 1\n",
    "    visits[\"filter_change\"] = fmask\n",
    "\n",
    "    # calculate slew times and identify expected overheads\n",
    "    visits, slewing = rn_sch.add_model_slew_times(\n",
    "        visits,\n",
    "        endpoints[\"efd\"],\n",
    "        model_settle=wait_before_slew + settle,\n",
    "        dome_crawl=True,\n",
    "        slew_while_changing_filter=False,\n",
    "    )\n",
    "    valid_overhead = np.min(\n",
    "        [\n",
    "            np.where(np.isnan(visits.slew_model.values), 0, visits.slew_model.values)\n",
    "            + max_scatter,\n",
    "            visits.visit_gap.values,\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    visits[\"overhead\"] = valid_overhead\n",
    "\n",
    "    # Need to remove faults for the first visit of the night or where there was a different program we didn't fetch\n",
    "    skipped_visits = np.concatenate(\n",
    "        [\n",
    "            np.array([0]),\n",
    "            np.where(visits.visit_id[:-1].values + 1 != visits.visit_id[1:].values)[0]\n",
    "            + 1,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fault = visits.visit_gap - valid_overhead\n",
    "    fault[skipped_visits] = np.nan\n",
    "    visits[\"fault_idle\"] = fault\n",
    "\n",
    "    visits.loc[skipped_visits, \"model_gap\"] = np.nan\n",
    "\n",
    "    # Pull lsst-dm excluded visit list to flag bad visits\n",
    "    bad_visit_ids = augment_visits.fetch_excluded_visits(\"lsstcam\")\n",
    "    visits[\"bad_flag\"] = np.zeros(len(visits), int)\n",
    "    idx = visits.query(\"visit_id in @bad_visit_ids\").index\n",
    "    visits.loc[idx, \"bad_flag\"] = 1\n",
    "    # Also pull bad visit lists from exposure log\n",
    "    ee = endpoints[\"exposure_log\"].query_log(\n",
    "        rn_dayobs.day_obs_to_time(day_obs_min), rn_dayobs.day_obs_to_time(day_obs_max)\n",
    "    )\n",
    "    if len(ee) > 0:\n",
    "\n",
    "        def make_visit_id(x):\n",
    "            return f\"{x.day_obs:d}{x.seq_num:05d}\"\n",
    "\n",
    "        exp_log_bad_visit_ids = (\n",
    "            ee.query(\"exposure_flag == 'junk'\").apply(make_visit_id, axis=1).values\n",
    "        )\n",
    "        if len(exp_log_bad_visit_ids) > 0:\n",
    "            idx = visits.query(\"visit_id in @exp_log_bad_visit_ids\").index\n",
    "            visits.loc[idx, \"bad_flag\"] = 1\n",
    "\n",
    "    # And flag close_loop visits as 'bad' for purposes of efficiency\n",
    "    idx = visits.query(\"observation_reason.str.contains('close_loop')\").index\n",
    "    visits.loc[idx, \"bad_flag\"] = 1\n",
    "\n",
    "    sci = visits.query(\"science_program in @programs\")\n",
    "    print(\n",
    "        \"all visits:\",\n",
    "        len(visits),\n",
    "        \"science visits:\",\n",
    "        len(visits.query(\"science_program in @programs\")),\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"Found no visits\")\n",
    "    print(\"The remainder of this notebook requires visits.\")\n",
    "\n",
    "## -- need to mark time associated with bad visits as fault somehow .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting this up early makes it easier to slot in all other values\n",
    "night_times = []\n",
    "for day_obs in day_obs_list:\n",
    "    dome_day = dome_open.query(\"day_obs == @day_obs\")\n",
    "    if (len(dome_day) == 0) or (\"sunset12\" not in dome_day.columns):\n",
    "        sunset, sunrise = rn_dayobs.day_obs_sunset_sunrise(day_obs, -12)\n",
    "        night_hours = (sunrise.mjd - sunset.mjd) * 24\n",
    "        open_hours = 0\n",
    "    else:\n",
    "        sunset = Time(dome_day.sunset12.iloc[0]).tai\n",
    "        sunrise = Time(dome_day.sunrise12.iloc[0]).tai\n",
    "        night_hours = dome_day.night_hours.iloc[0]\n",
    "        open_hours = dome_day.open_hours.sum()\n",
    "    closed_hours = night_hours - open_hours\n",
    "    night_times.append(\n",
    "        pd.Series(\n",
    "            {\n",
    "                \"sunset\": sunset.tai.mjd,\n",
    "                \"sunrise\": sunrise.tai.mjd,\n",
    "                \"night_hours\": night_hours,\n",
    "                \"open_hours\": open_hours,\n",
    "                \"closed_hours\": closed_hours,\n",
    "            },\n",
    "            name=day_obs,\n",
    "        )\n",
    "    )\n",
    "night_times = pd.DataFrame(night_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot expected slewtime vs. actual visit gap\n",
    "# Sometimes we want a subset of days ..\n",
    "\n",
    "print(\"Look at the visit gaps and expected visit gaps, for SCIENCE visits only:\")\n",
    "\n",
    "dayobs = visits.day_obs.unique()\n",
    "\n",
    "q = visits.query(\"science_program in @programs and day_obs in @dayobs\")\n",
    "total_time = (q.shut_time.sum() + q.overhead.sum() + q.fault_idle.sum()) / 3600\n",
    "total_onsky = q.exp_time.sum() / 3600\n",
    "total_req = (q.shut_time.sum() + q.overhead.sum()) / 3600\n",
    "total_fault_idle = q.fault_idle.sum() / 3600\n",
    "dd = pd.DataFrame(\n",
    "    [total_time, total_onsky, total_req, total_fault_idle, len(q), len(q) * 30 / 3600],\n",
    "    index=[\n",
    "        \"time for visits\",\n",
    "        \"onsky exptime\",\n",
    "        \"onsky+overhead\",\n",
    "        \"fault+idle_sci\",\n",
    "        \"nvis\",\n",
    "        \"estimate time onsky\",\n",
    "    ],\n",
    "    columns=[\"all \" + \"_\".join(programs)],\n",
    ")\n",
    "display(dd.T)\n",
    "\n",
    "print(\n",
    "    f\"Min/median/mean predicted overheads: {q.overhead.min():.2f} {q.overhead.median():.2f} {q.overhead.mean():.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Min/median/mean actual visit gaps: {q.visit_gap.min():.2f} {q.visit_gap.median():.2f} {q.visit_gap.mean():.2f}\"\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax = axes[0]\n",
    "ax.plot(q.visit_gap, q.slew_model, \"k.\")\n",
    "# ax.hexbin(q.visit_gap, q.slew_model, gridsize=200, extent=[0, 30, 0, 30], mincnt=1, vmin=0, vmax=10)\n",
    "x = np.arange(0, 500, 1)\n",
    "ax.plot(x, x, alpha=0.3)\n",
    "ax.fill_betweenx(x1=x + max_scatter, x2=x, y=x, color=\"pink\", alpha=0.2)\n",
    "ax.set_xlim(0, 30)\n",
    "ax.set_ylim(0, 30)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.set_xlabel(\"Visit gap (seconds)\")\n",
    "ax.set_ylabel(\"Predicted visit gap (seconds)\")\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(q.visit_gap, q.slew_model, \"k.\")\n",
    "x = np.arange(0, 500, 1)\n",
    "ax.plot(x, x, alpha=0.3)\n",
    "ax.fill_betweenx(x1=x + max_scatter, x2=x, y=x, color=\"pink\", alpha=0.2)\n",
    "# ax.set_xlim(0, 30)\n",
    "# ax.set_ylim(0, 30)\n",
    "ax.grid(alpha=0.4)\n",
    "ax.set_xlabel(\"Visit gap (seconds)\")\n",
    "ax.set_ylabel(\"Predicted visit gap (seconds)\")\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(q.slew_distance, q.model_gap, \"k.\")\n",
    "ax.set_ylim(-10, 10)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlabel(\"Slew distance (deg)\")\n",
    "_ = ax.set_ylabel(\"visit_gap - prediction (seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compare expected visit gap (without faults) to the v5.1 model visit gap:\")\n",
    "q = visits.query(\"science_program in @programs\")\n",
    "\n",
    "\n",
    "def slew_ratios(g):\n",
    "    slew_eff = (g.exp_time.sum()) / (g.dark_time.sum() + g.overhead.sum())\n",
    "    ideal_eff = (g.exp_time.sum()) / (g.dark_time.sum() + g.slew_model_ideal.sum())\n",
    "    med_gap = np.nanmedian((g.obs_start_mjd - g.prev_obs_end_mjd) * 24 * 60 * 60)\n",
    "    time_lost = (g.overhead.sum() - g.slew_model_ideal.sum()) / 60\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"slew_eff\": slew_eff,\n",
    "            \"ideal_eff\": ideal_eff,\n",
    "            \"slew_ratio\": slew_eff / ideal_eff,\n",
    "            \"med_gap\": med_gap,\n",
    "            \"slew_time_loss\": time_lost,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "visit_gap_eff = q.groupby(\"day_obs\")[\n",
    "    [\n",
    "        \"exp_time\",\n",
    "        \"dark_time\",\n",
    "        \"overhead\",\n",
    "        \"slew_model_ideal\",\n",
    "        \"obs_start_mjd\",\n",
    "        \"prev_obs_end_mjd\",\n",
    "    ]\n",
    "].apply(slew_ratios)\n",
    "\n",
    "night_times = night_times.join(visit_gap_eff, how=\"outer\")\n",
    "\n",
    "display(visit_gap_eff.round(2))\n",
    "\n",
    "print(\"mean values\")\n",
    "print(f\"Current max open-shutter-efficiency: {visit_gap_eff.slew_eff.mean(): 0.2f}\")\n",
    "print(\n",
    "    f\"Ideal model open-shutter-efficiency equivalent: {visit_gap_eff.ideal_eff.mean(): 0.2f}\"\n",
    ")\n",
    "print(f\"Ratio - slew / ideal {visit_gap_eff.slew_ratio.mean() :0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get narrative time lost logs - rely on OSs to only report values for night time\n",
    "time_lost_logs = endpoints[\"narrative_log\"].query_log(\n",
    "    rn_dayobs.day_obs_to_time(day_obs_min),\n",
    "    rn_dayobs.day_obs_to_time(day_obs_max),\n",
    "    {\"min_time_lost\": \"0.00001\"},\n",
    ")\n",
    "if len(time_lost_logs) > 0:\n",
    "    time_lost_logs = time_lost_logs.query(\"not component.str.contains('AuxTel')\")\n",
    "\n",
    "    def time_to_day_obs(x):\n",
    "        return rn_dayobs.day_obs_str_to_int(\n",
    "            rn_dayobs.time_to_day_obs(Time(x.date_begin, format=\"isot\", scale=\"utc\"))\n",
    "        )\n",
    "\n",
    "    time_lost_logs[\"day_obs\"] = time_lost_logs.apply(time_to_day_obs, axis=1)\n",
    "    log_fault = (\n",
    "        time_lost_logs.query(\"time_lost_type == 'fault'\")\n",
    "        .groupby(\"day_obs\")\n",
    "        .agg({\"time_lost\": \"sum\"})\n",
    "        .rename({\"time_lost\": \"log_fault\"}, axis=1)\n",
    "    )\n",
    "    log_weather = (\n",
    "        time_lost_logs.query(\"time_lost_type == 'weather'\")\n",
    "        .groupby(\"day_obs\")\n",
    "        .agg({\"time_lost\": \"sum\"})\n",
    "        .rename({\"time_lost\": \"log_weather\"}, axis=1)\n",
    "    )\n",
    "    log_lost = log_fault.merge(log_weather, how=\"outer\", on=\"day_obs\")\n",
    "else:\n",
    "    log_lost = None\n",
    "\n",
    "if log_lost is not None:\n",
    "    night_times = night_times.join(log_lost, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate values relating to visits and expected visit gaps\n",
    "\n",
    "fault_gap = 5 * 60  # seconds\n",
    "\n",
    "\n",
    "def time_active(g):\n",
    "    nn = night_times.loc[g.name]\n",
    "\n",
    "    # Estimate of all fault/idle time - expect higher idle during other surveys\n",
    "    all_fault_idle = round(g.fault_idle.sum() / 60 / 60, 2)\n",
    "    # Estimate all fault/idle time - but only where visit_gap > 5 minutes\n",
    "    gap_fault_idle = round(\n",
    "        g.query(\"visit_gap > @fault_gap\").fault_idle.sum() / 60 / 60, 2\n",
    "    )\n",
    "\n",
    "    # Estimate of time 'missing' from science at start or end of the night\n",
    "    fbs = g.query(\"science_program in @programs\")\n",
    "    if len(fbs) == 0:\n",
    "        twi_to_start = (nn.sunrise - nn.sunset) * 24\n",
    "        end_to_twi = 0\n",
    "    else:\n",
    "        twi_to_start = (fbs.obs_start_mjd.min() - nn.sunset) * 24\n",
    "        end_to_twi = (nn.sunrise - fbs.obs_end_mjd.max()) * 24\n",
    "\n",
    "    # Estimate time spent in FBS compared to time expected for these visits in FBS\n",
    "    time_in_fbs = (fbs.obs_end_mjd.max() - fbs.obs_start_mjd.min()) * 24\n",
    "    fbs_no_close_loop = fbs.query(\n",
    "        \"science_program in @programs and not observation_reason.str.contains('close_loop')\"\n",
    "    )\n",
    "    time_predict_in_fbs = (\n",
    "        (fbs_no_close_loop.dark_time.sum() + fbs_no_close_loop.slew_model_ideal.sum())\n",
    "        / 60\n",
    "        / 60\n",
    "    )\n",
    "    fbs_open_shutter_fraction = (fbs.exp_time.sum()) / (nn.night_hours * 60 * 60)\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"nvis\": len(g),\n",
    "            \"nvis_sci\": len(fbs),\n",
    "            \"delay_start\": twi_to_start,\n",
    "            \"early_end\": end_to_twi,\n",
    "            \"total_fault_idle\": all_fault_idle,\n",
    "            \"total_fault_idle_gap\": gap_fault_idle,\n",
    "            \"time_in_fbs\": time_in_fbs,\n",
    "            \"time_predict_in_fbs\": time_predict_in_fbs,\n",
    "            \"fbs_open_shutter\": fbs_open_shutter_fraction,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "fault_eff = visits.groupby(\"day_obs\").apply(time_active, include_groups=False)\n",
    "\n",
    "night_times = night_times.join(fault_eff, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some extrapolations for efficiency over the whole night\n",
    "\n",
    "# Estimate the fraction of the night used/run\n",
    "ratio_active = round(\n",
    "    (\n",
    "        night_times.night_hours\n",
    "        - night_times.delay_start\n",
    "        - night_times.early_end\n",
    "        - night_times.total_fault_idle_gap\n",
    "    )\n",
    "    / (night_times.night_hours),\n",
    "    2,\n",
    ")\n",
    "\n",
    "# Overall efficiency if we had used the whole night, minus faults, with slew efficiency at that night\n",
    "eff_all = round(ratio_active * night_times.slew_ratio, 2)\n",
    "\n",
    "\n",
    "# For FBS extrapolation, the FBS open shutter fraction already includes faults within the FBS and we don't want to include other faults\n",
    "ratio_avail = (\n",
    "    night_times.night_hours - night_times.delay_start - night_times.early_end\n",
    ") / night_times.night_hours\n",
    "\n",
    "eff_fbs = round(\n",
    "    night_times.time_predict_in_fbs / night_times.time_in_fbs * ratio_avail, 2\n",
    ")\n",
    "\n",
    "\n",
    "# An estimate of the simulation effectiveness ratio - using unscheduled downtime only\n",
    "eff_sim_ref = round((night_times.night_hours - 0.37) / night_times.night_hours, 2)\n",
    "\n",
    "effs = pd.DataFrame(\n",
    "    [ratio_active, ratio_avail, eff_all, eff_fbs, eff_sim_ref],\n",
    "    index=[\"ratio_active\", \"ratio_avail\", \"eff_all\", \"eff_fbs\", \"eff_sim_ref\"],\n",
    "    columns=day_obs_list,\n",
    ").T\n",
    "\n",
    "night_times = night_times.join(effs, how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"fault+idle (hours) - total: {night_times.total_fault_idle.sum():.2f} mean: {np.nanmean(night_times.total_fault_idle):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"fault+idle gap (hours) - total: {night_times.total_fault_idle_gap.sum():.2f} mean: {np.nanmean(night_times.total_fault_idle_gap):.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"log fault (hours) - total: {night_times.log_fault.sum():.2f} mean: {np.nanmean(night_times.log_fault):.2f}\"\n",
    ")\n",
    "\n",
    "# make an average ratio, with a fudge factor for time lost at ends of night\n",
    "print(f\"System availability estimate all: {np.nanmean(night_times.eff_all):.2f}\")\n",
    "print(f\"System availability estimate fbs: {np.nanmean(night_times.eff_fbs):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using baseline_v5.1.0_10yrs as the comparison\")\n",
    "fraction_wfd = 1692518.00 / 2075536.00\n",
    "fO_comparison = 762.00 / 825 * 0.9 / fraction_wfd\n",
    "print(f\"fraction WFD in this sim: {fraction_wfd:.2f}\")\n",
    "print(f\"median_nvis / 825 * 0.9 / fraction_wfd = {fO_comparison:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of above system availabity * fO_comparison info per night\n",
    "plt.figure(figsize=(12, 6))\n",
    "q = night_times[[\"eff_fbs\", \"eff_all\"]].fillna(0)\n",
    "x = np.arange(0, len(q))\n",
    "y = q[\"eff_fbs\"] * fO_comparison\n",
    "plt.plot(x, y, marker=\".\", label=\"efficiency fbs visits\")\n",
    "y = q[\"eff_all\"] * fO_comparison\n",
    "plt.plot(x, y, marker=\".\", label=\"efficiency all visits\")\n",
    "yy = np.nanmean(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            q[\"eff_all\"].values * fO_comparison,\n",
    "            q[\"eff_fbs\"].values * fO_comparison,\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "plt.axhline(yy, color=\"gray\", linestyle=\":\", label=\"mean\")\n",
    "_ = plt.xticks(x, q.index, rotation=90)\n",
    "_ = plt.ylabel(\"SA*fO\")\n",
    "_ = plt.legend(loc=(1.01, 0.5))\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "y = q[\"eff_fbs\"]\n",
    "_ = plt.hist(y, bins=30, alpha=0.5, label=\"efficiency fbs visits\")\n",
    "y = q[\"eff_all\"]\n",
    "_ = plt.hist(y, bins=30, alpha=0.5, label=\"efficiency all visits\")\n",
    "plt.xlabel(\"SA * fO\")\n",
    "plt.ylabel(\"Nnights\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
